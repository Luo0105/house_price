# 更新日志

本项目所有重要的更改都将记录在此文件中。

## [0.6.0] - 2025-07-22

### 新增 (Added)
- **扩充模型对比**: 在交叉验证框架下，新增了 `Random Forest` 和 `Ridge` (岭回归) 两个模型进行评估，使得最终的模型性能对比库更加完整和多样化。
- **项目可视化**: 
  - 在`README.md`中加入了专业的模型性能对比图表，包含5个模型的平均分和误差棒，用于直观展示性能和稳定性。
  - 使用Mermaid语法绘制了中英文双语的项目工作流图，清晰地展示了从数据加载到最终提交的每一个步骤。

### 优化 (Changed)
- **项目文档 (README)**: 对`README.md`文件进行了全面的升级和美化，使其更专业、更具可读性。
  - 在文件顶部加入了多个技术栈徽章 (Badges)，如Kaggle排名、Python版本、Scikit-learn等。
  - 重构了内容结构，增加了模型性能对比的可视化图表和最终排行榜表格。

### 修复 (Fixed)
- **模型兼容性问题**: 修复了因库版本不兼容，导致`Ridge`模型在交叉验证中报错的问题（通过明确指定求解器`solver='lsqr'`解决）。
- **文档渲染问题**: 修复了在`README.md`中绘制工作流图时的Mermaid语法解析错误，确保图表能被正确渲染。

## [0.5.0] - 2025-07-21

### 新增 (Added)
- **最终提交与成果**: 
  - 基于交叉验证的结果，选择最优的单模型（调优后的CatBoost）在**100%的完整训练数据**上进行重新训练，以最大化其性能。
  - 生成最终提交文件，并在Kaggle公开排行榜上取得了 **`0.12450`** 的优异官方分数，位列 **Top 13%**（约 650 / 5000+）。

### 优化 (Changed)
- **项目结构**: 将实验Notebook重构为V2版本，以交叉验证为核心，使整个实验流程更加清晰、专业和可复现。

## [0.4.0] - 2025-07-20

### 新增 (Added)
- **引入5折交叉验证 (K-Fold Cross-Validation)**:
  - 创建了可复用的交叉验证函数 `run_kfold_cv`，用于对任意模型进行标准化评估，取代了之前依赖单一验证集的评估方法。
  
### 优化 (Changed)
- **模型评估体系升级**: 
  - 通过更稳健的交叉验证确认，调优后的`CatBoost`模型以 **`0.11762`** 的平均分成为最强单模型，其表现优于XGBoost(`0.12101`)和LightGBM(`0.12370`)。
  - 验证了所有模型的标准差（Std Dev）都非常小，证明了特征工程的有效性和模型的稳定性。

## [0.3.0] - 2025-07-20

### 新增 (Added)
- **终极特征工程**: 对特征工程函数进行了全面升级。
  - 将`MSSubClass`（建筑类别）正确地转换为类别特征处理。
  - 对所有有序质量特征（如`ExterQual`）进行了数值映射，以保留其等级信息。
  - 创造了多个交互特征（如`Qual_x_TotalSF`）来捕捉非线性关系。
  - 对所有倾斜度较高的数值特征进行了对数变换（`log1p`），使其更接近正态分布。
- **数据清洗**: 根据高分方案的经验，移除了两个`GrLivArea` > 4000 的著名异常值。

### 优化 (Changed)
- **超参数调优**: 使用`GridSearchCV`对三大梯度提升模型进行了精细的自动化参数调优。
  - 调优后的 `XGBoost` 取得了 `0.12242` 的优异成绩。
  - 调优后的 `CatBoost` 表现最为出色，凭借其强大的类别特征处理能力，成为新的单模型王者，分数为 **`0.12171`**。
- **终极模型融合**: 对三个**调优后**的“巅峰状态”模型（CatBoost, XGBoost, LightGBM）进行了加权平均融合。
  - 最终在本地验证集上取得了 **`0.12005`** 的项目最佳分数

### 修复 (Fixed)
- 解决了在处理测试集时，因出现训练集未见的类别而导致的特征数量不匹配的`ValueError`。
- 修复了在对数变换时，因数据存在负值而产生的`RuntimeWarning`，使整个数据处理流程更加健壮。

## [0.2.0] - 2025-07-19

### 新增 (Added)
- **探索新模型**: 引入了梯度提升模型进行实验。
  - 首次使用 `LightGBM` 模型，分数显著提升至 **0.13702**。
  - 尝试了 `XGBoost` 模型，并使用“提前停止”策略，得到分数 **0.13893**。
- **模型融合**: 对LightGBM和XGBoost的预测结果进行了简单的50/50加权平均，进一步将分数优化至 **0.13590**。

### 优化 (Changed)
- **高级特征工程**:
  - 对缺失值进行了“智能填充”，例如将泳池、车库、地下室等特征的`NaN`值填充为代表“没有”的类别（如 'None' 或 0），而不是用众数或中位数填充。
  - 创造了多个新特征，如`TotalSF` (总面积), `HouseAge` (房龄) 和 `TotalBath` (总浴室数)，以提供更丰富的信息给模型。


## [0.1.0] - 2025-07-18

### 新增 (Added)
- **项目创建**: 创建了此项目仓库，用于预测 Ames 的房价。
- **搭建基准线 (Baseline)**:
  - **预处理**: 使用了相对简单的策略，即对数值型特征的缺失值用“中位数”填充，对类别型特征用“众数”填充，并对所有类别特征进行独热编码。
  - **模型**: 使用 `RandomForestRegressor` (随机森林回归器) 作为初始模型。
  - **初始分数**: 在本地验证集上取得了 **0.14561** 的 RMSLE 分数，为后续优化提供了一个坚实的起点。
