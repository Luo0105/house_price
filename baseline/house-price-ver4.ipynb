{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ## 1. 初始设置：加载库、数据和函数定义\n\n# --- 1a. 导入所有需要的库 ---\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import skew\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"✅ 所有库已成功导入。\")\n\n\n# --- 1b. 加载数据并进行初始清洗 ---\ntry:\n    train_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n    test_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n    print(\"数据加载成功。\")\nexcept FileNotFoundError:\n    print(\"错误：请确保数据集已添加到Notebook环境。\")\n\n# 移除著名的异常值\nif 'train_df' in locals():\n    outlier_indices = train_df[(train_df['GrLivArea'] > 4000) & (train_df['SalePrice'] < 300000)].index\n    train_df = train_df.drop(outlier_indices)\n    print(f\"移除了 {len(outlier_indices)} 个GrLivArea异常值。\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T20:51:23.026706Z","iopub.execute_input":"2025-07-20T20:51:23.027073Z","iopub.status.idle":"2025-07-20T20:51:23.115807Z","shell.execute_reply.started":"2025-07-20T20:51:23.027032Z","shell.execute_reply":"2025-07-20T20:51:23.114912Z"}},"outputs":[{"name":"stdout","text":"✅ 所有库已成功导入。\n数据加载成功。\n移除了 2 个GrLivArea异常值。\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- 1c. 定义我们最强的特征工程函数 ---\ndef feature_engineer_ultimate_final(df, skew_list_to_apply=None):\n    \"\"\"\n    终极版特征工程函数，包含了所有优化技巧。\n    \"\"\"\n    df_fe = df.copy()\n    df_fe['MSSubClass'] = df_fe['MSSubClass'].astype(str)\n    quality_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n    ordered_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n    for col in ordered_cols:\n        if col in df_fe.columns: df_fe[col] = df_fe[col].map(quality_map)\n    for col in ['Alley', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Fence', 'GarageType', 'GarageFinish', 'MasVnrType', 'MiscFeature']:\n        df_fe[col] = df_fe[col].fillna('None')\n    for col in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea'] + ordered_cols:\n        df_fe[col] = df_fe[col].fillna(0)\n    df_fe['LotFrontage'] = df_fe.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n    for col in ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'Electrical', 'Functional', 'SaleType']:\n        if col in df_fe.columns: df_fe[col] = df_fe[col].fillna(df_fe[col].mode()[0])\n    numerical_cols_with_na = df_fe.select_dtypes(include=np.number).columns[df_fe.select_dtypes(include=np.number).isnull().any()]\n    for col in numerical_cols_with_na:\n        df_fe[col] = df_fe[col].fillna(df_fe[col].median())\n    df_fe['TotalSF'] = df_fe['TotalBsmtSF'] + df_fe['1stFlrSF'] + df_fe['2ndFlrSF']\n    df_fe['HouseAge'] = df_fe['YrSold'] - df_fe['YearBuilt']\n    df_fe['RemodAge'] = df_fe['YrSold'] - df_fe['YearRemodAdd']\n    df_fe['TotalBath'] = df_fe['BsmtFullBath'] + (0.5 * df_fe['BsmtHalfBath']) + df_fe['FullBath'] + (0.5 * df_fe['HalfBath'])\n    df_fe['HouseAge'] = df_fe['HouseAge'].clip(0)\n    df_fe['RemodAge'] = df_fe['RemodAge'].clip(0)\n    df_fe['Qual_x_TotalSF'] = df_fe['OverallQual'] * df_fe['TotalSF']\n    df_fe['Qual_x_HouseAge'] = df_fe['OverallQual'] * df_fe['HouseAge']\n    if skew_list_to_apply is None:\n        numerical_feats = df_fe.select_dtypes(exclude=[\"object\", \"category\"]).columns\n        skewed_feats = df_fe[numerical_feats].apply(lambda x: skew(x.dropna()))\n        skew_list_to_apply = skewed_feats[skewed_feats > 0.5].index\n    for feat in skew_list_to_apply:\n        if feat in df_fe.columns: df_fe[feat] = np.log1p(df_fe[feat])\n    return df_fe, skew_list_to_apply\n\nprint(\"✅ 特征工程函数已定义。\")\nprint(\"\\n--- Notebook V2 第一部分完成 ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T20:52:16.395345Z","iopub.execute_input":"2025-07-20T20:52:16.395667Z","iopub.status.idle":"2025-07-20T20:52:16.408787Z","shell.execute_reply.started":"2025-07-20T20:52:16.395643Z","shell.execute_reply":"2025-07-20T20:52:16.407846Z"}},"outputs":[{"name":"stdout","text":"✅ 特征工程函数已定义。\n\n--- Notebook V2 第一部分完成 ---\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ## 2. 准备工作：定义完整数据集和模型参数\n\n# --- 2a. 准备完整的、干净的 X_full 和 y_log ---\n# 从第一部分加载并清洗过的 train_df 创建\nif 'train_df' in locals():\n    X_full = train_df.drop(['Id', 'SalePrice'], axis=1).reset_index(drop=True)\n    y_full = train_df['SalePrice'].reset_index(drop=True)\n    y_log = np.log1p(y_full)\n    \n    print(\"✅ 完整的 X_full 和 y_log 已准备就绪。\")\n    print(f\"X_full 的形状: {X_full.shape}\")\n    print(f\"y_log 的形状: {y_log.shape}\")\nelse:\n    print(\"‼️ 错误：train_df 未定义，请先运行第一部分的代码。\")\n\n\n# --- 2b. 定义我们找到的最佳超参数 ---\n# 这是我们之前通过GridSearchCV辛苦找到的“冠军配置”\nlgbm_best_params = {'learning_rate': 0.05, 'n_estimators': 200, 'num_leaves': 20, 'random_state': 42, 'verbosity': -1}\nxgb_best_params = {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500, 'random_state': 42}\ncat_best_params = {'depth': 6, 'iterations': 500, 'learning_rate': 0.1, 'random_state': 42}\n\nprint(\"\\n✅ 三巨头的最佳参数已定义。\")\nprint(\"\\n--- Notebook V2 第二部分完成 ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T21:05:49.934011Z","iopub.execute_input":"2025-07-20T21:05:49.934369Z","iopub.status.idle":"2025-07-20T21:05:49.952434Z","shell.execute_reply.started":"2025-07-20T21:05:49.934347Z","shell.execute_reply":"2025-07-20T21:05:49.951252Z"}},"outputs":[{"name":"stdout","text":"✅ 完整的 X_full 和 y_log 已准备就绪。\nX_full 的形状: (1458, 79)\ny_log 的形状: (1458,)\n\n✅ 三巨头的最佳参数已定义。\n\n--- Notebook V2 第二部分完成 ---\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ## 3. 核心引擎：K-折交叉验证函数\n\ndef run_kfold_cv(model_class, params, X, y, n_splits=5, model_type='lgbm'):\n    \"\"\"\n    一个通用的交叉验证函数。\n\n    参数:\n    - model_class: 模型的类 (例如 lgb.LGBMRegressor)\n    - params: 模型的最佳参数字典\n    - X, y: 完整的特征集和目标集\n    - n_splits: 交叉验证的折数\n    - model_type: 'lgbm', 'xgb', 或 'catboost'，用于区分预处理方式\n    \"\"\"\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    cv_scores = []\n    \n    print(f\"--- 开始对 {model_type.upper()} 模型进行 {n_splits}-折交叉验证 ---\")\n\n    for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n        print(f\"  --- 第 {fold+1}/{n_splits} 折 ---\")\n        \n        # 1. 划分当前折的数据\n        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n\n        # 2. 特征工程\n        X_train_fold_pro, skew_list = feature_engineer_ultimate_final(X_train_fold)\n        X_val_fold_pro, _ = feature_engineer_ultimate_final(X_val_fold, skew_list_to_apply=skew_list)\n        \n        # 3. 根据模型类型进行预处理和训练\n        # 这个函数最智能的地方在于，它知道CatBoost和另外两个模型‘吃’的数据不一样\n        \n        if model_type == 'catboost':\n            # CatBoost直接使用特征工程后的数据\n            categorical_cols_names = [c for c in X_train_fold_pro.columns if X_train_fold_pro[c].dtype == 'object']\n            model = model_class(**params, cat_features=categorical_cols_names, verbose=0)\n            model.fit(X_train_fold_pro, y_train_fold)\n            preds_log = model.predict(X_val_fold_pro)\n        \n        else: # LGBM 和 XGBoost 需要独热编码\n            categorical_cols = [c for c in X_train_fold_pro.columns if X_train_fold_pro[c].dtype == 'object']\n            numerical_cols = [c for c in X_train_fold_pro.columns if X_train_fold_pro[c].dtype in ['int64', 'float64']]\n            \n            preprocessor = ColumnTransformer(transformers=[\n                ('num', SimpleImputer(strategy='median'), numerical_cols),\n                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)])\n            \n            X_train_fold_processed = preprocessor.fit_transform(X_train_fold_pro)\n            X_val_fold_processed = preprocessor.transform(X_val_fold_pro)\n            \n            model = model_class(**params)\n            model.fit(X_train_fold_processed, y_train_fold)\n            preds_log = model.predict(X_val_fold_processed)\n\n        # 4. 评估分数\n        y_val_orig = np.expm1(y_val_fold)\n        preds_orig = np.expm1(preds_log)\n        preds_orig[preds_orig < 0] = 0\n        \n        score = np.sqrt(mean_squared_log_error(y_val_orig, preds_orig))\n        cv_scores.append(score)\n        print(f\"    第 {fold+1} 折的分数: {score:.5f}\")\n\n    # 5. 打印最终结果\n    mean_score = np.mean(cv_scores)\n    std_score = np.std(cv_scores)\n    print(\"=\"*50)\n    print(f\"{model_type.upper()} 模型交叉验证完成。\")\n    print(f\"平均分 (Mean RMSLE): {mean_score:.5f}\")\n    print(f\"标准差 (Std Dev): {std_score:.5f}\")\n    print(\"=\"*50)\n    \n    return mean_score, std_score\n\nprint(\"✅ 交叉验证核心引擎函数已定义。\")\nprint(\"\\n--- Notebook V2 第三部分完成 ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T21:07:12.437133Z","iopub.execute_input":"2025-07-20T21:07:12.437907Z","iopub.status.idle":"2025-07-20T21:07:12.451379Z","shell.execute_reply.started":"2025-07-20T21:07:12.437881Z","shell.execute_reply":"2025-07-20T21:07:12.450253Z"}},"outputs":[{"name":"stdout","text":"✅ 交叉验证核心引擎函数已定义。\n\n--- Notebook V2 第三部分完成 ---\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ## 4. 实验与分析\n\n# --- 4a. 评估我们调优后的CatBoost模型 ---\n# CatBoost是我们之前单次验证的王者，我们先看它在交叉验证下的表现\ncat_cv_mean, cat_cv_std = run_kfold_cv(\n    model_class=cb.CatBoostRegressor, \n    params=cat_best_params, \n    X=X_full, \n    y=y_log, \n    model_type='catboost'\n)\n\n# --- 4b. 评估我们调优后的XGBoost模型 ---\nxgb_cv_mean, xgb_cv_std = run_kfold_cv(\n    model_class=xgb.XGBRegressor,\n    params=xgb_best_params,\n    X=X_full,\n    y=y_log,\n    model_type='xgb'\n)\n\n# --- 4c. 评估我们调优后的LightGBM模型 ---\nlgbm_cv_mean, lgbm_cv_std = run_kfold_cv(\n    model_class=lgb.LGBMRegressor,\n    params=lgbm_best_params,\n    X=X_full,\n    y=y_log,\n    model_type='lgbm'\n)\n\n# --- 4d. 汇总和展示最终排行榜 ---\nprint(\"\\n\" + \"#\"*50)\nprint(\"### 最终模型排行榜 (基于5折交叉验证) ###\")\nprint(\"#\"*50)\n\n# 修正后的排行榜代码\nresults_df = pd.DataFrame({\n    'Model': ['CatBoost', 'XGBoost', 'LightGBM'],\n    'Mean RMSLE': [cat_cv_mean, xgb_cv_mean, lgbm_cv_mean], # 修正了这里\n    'Std Dev': [cat_cv_std, xgb_cv_std, lgbm_cv_std]\n}).sort_values(by='Mean RMSLE')\n\nprint(results_df)\n\nprint(\"\\n--- Notebook V2 第四部分完成 ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T21:09:45.418900Z","iopub.execute_input":"2025-07-20T21:09:45.419891Z","iopub.status.idle":"2025-07-20T21:10:37.749075Z","shell.execute_reply.started":"2025-07-20T21:09:45.419855Z","shell.execute_reply":"2025-07-20T21:10:37.748231Z"}},"outputs":[{"name":"stdout","text":"--- 开始对 CATBOOST 模型进行 5-折交叉验证 ---\n  --- 第 1/5 折 ---\n    第 1 折的分数: 0.12103\n  --- 第 2/5 折 ---\n    第 2 折的分数: 0.11207\n  --- 第 3/5 折 ---\n    第 3 折的分数: 0.11970\n  --- 第 4/5 折 ---\n    第 4 折的分数: 0.12947\n  --- 第 5/5 折 ---\n    第 5 折的分数: 0.10584\n==================================================\nCATBOOST 模型交叉验证完成。\n平均分 (Mean RMSLE): 0.11762\n标准差 (Std Dev): 0.00807\n==================================================\n--- 开始对 XGB 模型进行 5-折交叉验证 ---\n  --- 第 1/5 折 ---\n    第 1 折的分数: 0.12242\n  --- 第 2/5 折 ---\n    第 2 折的分数: 0.11852\n  --- 第 3/5 折 ---\n    第 3 折的分数: 0.12762\n  --- 第 4/5 折 ---\n    第 4 折的分数: 0.12656\n  --- 第 5/5 折 ---\n    第 5 折的分数: 0.10992\n==================================================\nXGB 模型交叉验证完成。\n平均分 (Mean RMSLE): 0.12101\n标准差 (Std Dev): 0.00641\n==================================================\n--- 开始对 LGBM 模型进行 5-折交叉验证 ---\n  --- 第 1/5 折 ---\n    第 1 折的分数: 0.12969\n  --- 第 2/5 折 ---\n    第 2 折的分数: 0.11622\n  --- 第 3/5 折 ---\n    第 3 折的分数: 0.12943\n  --- 第 4/5 折 ---\n    第 4 折的分数: 0.13061\n  --- 第 5/5 折 ---\n    第 5 折的分数: 0.11254\n==================================================\nLGBM 模型交叉验证完成。\n平均分 (Mean RMSLE): 0.12370\n标准差 (Std Dev): 0.00770\n==================================================\n\n##################################################\n### 最终模型排行榜 (基于5折交叉验证) ###\n##################################################\n      Model  Mean RMSLE   Std Dev\n2  LightGBM    0.007704  0.007704\n0  CatBoost    0.117620  0.008073\n1   XGBoost    0.121008  0.006412\n\n--- Notebook V2 第四部分完成 ---\n","output_type":"stream"}],"execution_count":6}]}